{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce76236-abfb-4407-9832-3e72851828d0",
   "metadata": {},
   "source": [
    "# Random Forest. Using a more sophisticated machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206b511-ba2e-4e1c-9ca6-0b75e3a05c5d",
   "metadata": {},
   "source": [
    "Usando un Algoritmo de ML mas sofisticado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5986b12-12fc-4fcf-9518-b117a32d6088",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "### Introducción\n",
    "\n",
    "Los **decision trees** te plantean una decisión complicada. Un árbol profundo con muchas hojas tenderá al **overfitting**, ya que cada predicción se basa en datos históricos de solo unas pocas viviendas en su hoja. En cambio, un árbol poco profundo con pocas hojas tendrá un rendimiento pobre porque no logra capturar suficientes diferencias en los datos originales, lo que conduce al **underfitting**.\n",
    "\n",
    "Incluso las técnicas de modelado más sofisticadas se enfrentan a esta tensión entre **underfitting** y **overfitting**. Sin embargo, muchos modelos incorporan ideas ingeniosas que permiten obtener un mejor rendimiento. En este caso, veremos el **random forest** como ejemplo.\n",
    "\n",
    "El **random forest** utiliza muchos árboles y realiza una predicción promediando los resultados de cada árbol. En general, ofrece una **predictive accuracy** mucho mayor que un único **decision tree** y suele funcionar bien con los parámetros por defecto. A medida que sigas avanzando, descubrirás otros modelos con un rendimiento aún mejor, aunque muchos de ellos son sensibles a una correcta elección de sus parámetros.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cfdc5-b1f2-4872-a43a-37960b51813b",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/separador.png\" alt=\"Separador\" width=200\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744881d8-515f-4364-8d34-bfaefdae8a26",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44319645-4dcc-40f2-8ec5-b2946721d73e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#E6F4EA; padding:12px; border-radius:4px;\">\n",
    "\n",
    "\n",
    "Ya has visto varias veces el código para cargar los datos. Al finalizar el proceso de **data loading**, disponemos de las siguientes variables:\n",
    "\n",
    "- **train_X**\n",
    "- **val_X**\n",
    "- **train_y**\n",
    "- **val_y**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e629d6b8-c16e-4609-9432-4d24c43af55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# cargando data\n",
    "melbourne_file_path=\"data/melb_data.csv\"\n",
    "melbourne_data=pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Quitando filas con NaN\n",
    "melbourne_data=melbourne_data.dropna(axis=0)\n",
    "\n",
    "# Eligiendo Target y Features\n",
    "y=melbourne_data.Price\n",
    "melbourne_features=[\"Rooms\",\"Bathroom\",\"Landsize\",\"BuildingArea\",\"YearBuilt\",\"Lattitude\",\"Longtitude\"]\n",
    "X=melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e6b35e-3a4b-43be-a082-205ff22828b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir los datos en datos de entrenamiento y validación, tanto para las features como para el target\n",
    "# la división se basa en un generador de números aleatorios. Proporcionar un valor numérico\n",
    "# al argumento random_state garantiza que obtengamos la misma división cada vez que\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y=train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaea5d3-6122-4fd5-a16e-1e435c862cc9",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#E6F4EA; padding:12px; border-radius:4px;\">\n",
    "\n",
    "Construimos un modelo de **random forest** de forma similar a como construimos un **decision tree** en **scikit-learn**, pero esta vez utilizando la clase **RandomForestRegressor** en lugar de **DecisionTreeRegressor**.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb7bf97-0815-451b-8736-1c852b3ae7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191669.7536453626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model=RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds=forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63297fb-558d-4e65-9996-4131033b0080",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Es probable que todavía haya margen de mejora, pero este resultado supone una mejora importante respecto al mejor error del **decision tree**, que era de 250 000. Existen **parameters** que permiten modificar el rendimiento del **Random Forest**, de forma similar a como ajustamos la **maximum depth** de un único **decision tree**. Sin embargo, una de las mejores características de los modelos **Random Forest** es que, por lo general, funcionan razonablemente bien incluso sin realizar este **tuning**.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d831ea-79fd-4d28-a4e9-8c8c8e92be27",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/separador.png\" alt=\"Separador\" width=200\"/>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
