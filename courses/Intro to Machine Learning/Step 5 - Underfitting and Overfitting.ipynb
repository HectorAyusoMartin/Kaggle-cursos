{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890fe3f2-7b11-4bc7-ad23-33a83cb31402",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting. Fine-tune your model for better perfomance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c69e2d-1e01-42e4-9cb6-e85e17781eeb",
   "metadata": {},
   "source": [
    "Al final de este paso entenderás los conceptos de **underfitting** y **overfitting**, y sabrás cómo aplicar estas ideas para hacer que tus modelos sean más precisos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972e192-8321-4df7-98fd-5bf110584bb8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "\n",
    "### Experimentar con distintos modelos\n",
    "\n",
    "Ahora que tienes una forma fiable de medir la precisión de un modelo, puedes experimentar con modelos alternativos y comprobar cuál ofrece mejores predicciones. Pero, ¿qué alternativas tienes?\n",
    "\n",
    "En la documentación de **scikit-learn** puedes ver que el modelo de **decision tree** tiene muchas opciones (más de las que necesitarás durante bastante tiempo). Las opciones más importantes determinan la **profundidad del árbol**.\n",
    "\n",
    "Recuerda de la primera lección que la profundidad de un árbol indica cuántas divisiones (*splits*) realiza antes de llegar a una predicción.  \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e825db6-e505-4d67-a4d6-e9945fc7b41a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "En la práctica, no es raro que un árbol tenga unas **10 divisiones (splits)** entre el nivel superior (todas las viviendas) y una hoja. A medida que el árbol se hace más profundo, el dataset se va dividiendo en hojas que contienen cada vez **menos viviendas**.\n",
    "\n",
    "Si un árbol tuviera solo **1 split**, dividiría los datos en **2 grupos**.  \n",
    "Si cada uno de esos grupos se divide otra vez, obtendríamos **4 grupos**.  \n",
    "Si volvemos a dividir cada uno, tendríamos **8 grupos**.  \n",
    "\n",
    "Si seguimos duplicando el número de grupos añadiendo más splits en cada nivel, al llegar al nivel 10 tendríamos:\n",
    "\n",
    "2¹⁰ = **1024 grupos (hojas)**.\n",
    "\n",
    "Cuando dividimos las viviendas en tantas hojas, cada hoja contiene muy pocas casas. Las hojas con muy pocos datos hacen predicciones muy cercanas a los valores reales de esas casas concretas, pero suelen ser **muy poco fiables para datos nuevos**, porque cada predicción se basa en muy pocos ejemplos.\n",
    "\n",
    "Este fenómeno se llama **overfitting**: el modelo se ajusta casi perfectamente a los datos de entrenamiento, pero funciona mal con datos de validación o datos nuevos.\n",
    "\n",
    "En el extremo contrario, si hacemos el árbol **muy poco profundo**, no divide las viviendas en grupos suficientemente distintos.\n",
    "\n",
    "Por ejemplo, si el árbol solo divide las casas en **2 o 4 grupos**, cada grupo sigue conteniendo viviendas muy diferentes entre sí. Como resultado, las predicciones pueden ser muy malas para la mayoría de las casas, incluso en los datos de entrenamiento (y también en validación, por la misma razón).\n",
    "\n",
    "Cuando un modelo no consigue capturar patrones y diferencias importantes en los datos y funciona mal incluso con los datos de entrenamiento, hablamos de **underfitting**.\n",
    "\n",
    "Como lo que realmente nos importa es la precisión en **datos nuevos**, que estimamos usando los datos de validación, buscamos un punto intermedio entre **underfitting** y **overfitting**. Visualmente, queremos encontrar el punto más bajo de la curva de validación (la curva roja) en la figura.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802bfa9-e7a6-4b26-a0a1-4aa143761ac6",
   "metadata": {},
   "source": [
    "<img src=\"assets/1.png\" alt=\"imagen\" style=\"max-width:50%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa84b5-383f-4a4d-93ca-22b511fbca54",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Existen varias alternativas para controlar la profundidad de un árbol, y muchas de ellas permiten que algunas ramas del árbol tengan mayor profundidad que otras. Sin embargo, el argumento **max_leaf_nodes** ofrece una forma muy sensata de controlar el equilibrio entre **overfitting** y **underfitting**.\n",
    "\n",
    "Cuantas más hojas permitimos que tenga el modelo, más nos desplazamos desde la zona de **underfitting** hacia la zona de **overfitting** en la gráfica anterior.\n",
    "\n",
    "Podemos usar una **función auxiliar** para comparar los valores de **MAE** obtenidos con distintos valores de **max_leaf_nodes**.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9ee94c-0970-4fc4-9fbf-17cc66a4fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49e8f57-273c-4f66-9552-4810f304a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_mae(numero_nodos, train_X, val_X, train_y, val_y):\n",
    "    modelo=DecisionTreeRegressor(max_leaf_nodes=numero_nodos,random_state=0)\n",
    "    modelo.fit(train_X,train_y)\n",
    "    prediccion=modelo.predict(val_X)\n",
    "    mae=mean_absolute_error(val_y,prediccion)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a225b3-88f8-469c-9664-5154c00afb0e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "Los datos se cargan en **train_X**, **val_X**, **train_y** y **val_y** usando el código que ya has visto (y que ya has escrito anteriormente).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4281bc5a-6d75-4e43-8ea4-ec20021482de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Code Runs At This Point\n",
    "import pandas as pd\n",
    "    \n",
    "# Load data\n",
    "melbourne_file_path = 'data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a098a51-6512-4a58-9299-3c5b57935073",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "Podemos usar un **bucle for** para comparar la precisión de modelos construidos con distintos valores de **max_leaf_nodes**.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5aa343a-562d-4796-9505-4e651a30d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\n",
      " \n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171\n",
      " \n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495\n",
      " \n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  255575\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Comparando MAE con diferentes valores de max_leaf_nodes\n",
    "for max_leaf_nodes in [5,50,500,5000]:\n",
    "    my_mae=obtener_mae(max_leaf_nodes, train_X,val_X,train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n",
    "    print(\" \")\n",
    "    \n",
    "    #print(f\"Numero de nodos: {max_leaf_nodes} | Mean Absolute Error = {my_mae}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a7d95-7767-4c1b-b092-ebaadd74fd08",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "De las opciones analizadas, **500** es el número óptimo de hojas.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66137bb4-2c7a-417d-ac51-4c3129e585e8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"assets/separador.png\" alt=\"Separador\" width=300\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cf6f5-cc34-4493-83bf-5b8f2ba7be10",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFF4CC; padding:12px; border-radius:4px;\">\n",
    "\n",
    "Conclusión\n",
    "\n",
    "La idea clave es la siguiente: los modelos pueden sufrir uno de estos dos problemas:\n",
    "\n",
    "- **Overfitting**: capturan patrones espurios que no se repetirán en el futuro, lo que conduce a predicciones menos precisas.\n",
    "- **Underfitting**: no consiguen capturar patrones relevantes, lo que también provoca predicciones poco precisas.\n",
    "\n",
    "Para medir la precisión real de un modelo usamos **validation data**, que no se utiliza durante el entrenamiento. Esto nos permite probar muchos modelos candidatos y quedarnos con el que ofrece el mejor rendimiento.\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
